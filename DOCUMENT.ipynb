{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Stefano Pigozzi | Tema Data Analytics | Big Data Analytics | A.A. 2022/2023 | Unimore ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attività online correlata all'avanzare della pandemia COVID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Data processing e exploratory data analytics su dataset provenienti da più sorgenti\n",
    "> \n",
    "> L’attività da svolgere consiste nel:\n",
    "> 1. Scegliere due o più dataset provenienti da due o più sorgenti.  \n",
    ">     * Il dataset finale deve essere costituito almeno da due file.\n",
    "> 2. Usando [pandas](https://pandas.pydata.org/) implementare le operazioni di data processing necessarie (principalmente join e selezioni) per mettere in collegamento i dataset e per preparare i dati al passo successivo\n",
    "> 3. Usando pacchetti Python quali [pandas](https://pandas.pydata.org/), [scipy](https://scipy.org/), [matplotlib](https://matplotlib.org/) e [seaborn](https://seaborn.pydata.org/) implementare attività di data cleaning, exploratory data analysis estraendo dati statistici e di visualizzazione dei risultati attraverso il quale sia possibile \"raccontare qualcosa sui dati\" (storytelling), eventualmente partendo da dei quesiti di ricerca. L'uso\n",
    "dei pacchetti non deve necessariamente essere limitato alle istruzioni viste a lezione. Le documentazioni dei pacchetti stessi e i volumi messi a disposizione su Dolly fornisco spunti d’uso interessanti!\n",
    "> 4. Produrre un notebook Jupyter (https://jupyter.org/) che contenga:\n",
    ">     * una introduzione all’argomento scelto, alle sorgenti dati e agli obiettivi del progetto specificando\n",
    "eventualmente i quesiti di ricerca\n",
    ">     * una sezione per ogni fase del progetto di data analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Abstract"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<!-- TODO -->"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installazione requisiti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per funzionare, questo progetto necessita di alcuni package Python, scaricabili da [PyPI](https://pypi.org/).\n",
    "\n",
    "In particolare:\n",
    "\n",
    "* [numpy](https://pypi.org/project/numpy/1.23.5/)\n",
    "* [scipy](https://pypi.org/project/scipy/1.9.3/)\n",
    "* [pandas](https://pypi.org/project/pandas/1.5.2/)\n",
    "* [matplotlib](https://pypi.org/project/matplotlib/3.6.2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.23.5 scipy==1.9.3 pandas==1.5.2 matplotlib==3.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nella seguenti celle, si effettua l'`import` di tutti i package utilizzati, in modo da poterli utilizzare nel presente documento Jupyter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si importano anche alcuni package della standard library di Python utili allo sviluppo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import typing as t\n",
    "t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import io\n",
    "io"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduzione"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<!-- TODO -->"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fonti dati"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Google Trends"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Google Trends](https://trends.google.com/trends/) è un servizio messo a disposizione da Google che permette di ispezionare il volume di ricerca nel tempo e nello spazio per dati termini.\n",
    "\n",
    "Selezionato un termine o un argomento di ricerca, è possibile esportare un file CSV contenente il volume relativo di ricerca nel tempo, con !!!intervalli!!! variabili da 1 mese a 1 minuto."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Esempio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si allega un esempio di file CSV [esportato da Google Trends per la ricerca \"Google\"](https://trends.google.com/trends/explore?date=all&q=Google):\n",
    "\n",
    "```csv\n",
    "Categoria: Tutte le categorie\n",
    "\n",
    "Mese,Google: (Tutto il mondo)\n",
    "2004-01,6\n",
    "2004-02,6\n",
    "2004-03,7\n",
    "2004-04,8\n",
    "2004-05,7\n",
    "2004-06,7\n",
    "2004-07,7\n",
    "2004-08,7\n",
    "2004-09,8\n",
    "2004-10,8\n",
    "2004-11,8\n",
    "2004-12,8\n",
    "2005-01,8\n",
    "2005-02,9\n",
    "[...]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importazione dati"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si definisce una funzione, `import_gtrends`, in grado di caricare dati scaricati da Google Trends in un [`pandas.DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def import_gtrends(fd: t.IO[str]) -> pandas.DataFrame:\n",
    "   \"\"\"\n",
    "   Import a Google Trends CSV file into a :class:`pandas.Series`.\n",
    "\n",
    "   :param fd: The file descriptor of the CSV file.\n",
    "   :return: The imported :class:`pandas.Series`.\n",
    "   \"\"\"\n",
    "   return pandas.read_csv(fd, sep=\",\", header=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si fornisce un esempio del funzionamento di questa funzione:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/gtrends/google-worldwide.csv\") as file:\n",
    "   google_worldwide = import_gtrends(file)\n",
    "\n",
    "google_worldwide"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Telegram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Telegram](https://telegram.org/), per conformità al GDPR, permette di [esportare i contenuti di una o più chat](https://t.me/gdprbot) in cui si è presenti in un file JSON leggibile da calcolatori."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Esempio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si allega un esempio di file JSON esportato da Telegram per una chat creata appositamente per lo scopo:\n",
    "\n",
    "```json\n",
    "{\n",
    " \"name\": \"Esempio\",\n",
    " \"type\": \"private_group\",\n",
    " \"id\": 660884870,\n",
    " \"messages\": [\n",
    "  {\n",
    "   \"id\": 1531670,\n",
    "   \"type\": \"service\",\n",
    "   \"date\": \"2022-12-02T14:49:03\",\n",
    "   \"date_unixtime\": \"1669988943\",\n",
    "   \"actor\": \"Steffo\",\n",
    "   \"actor_id\": \"user25167391\",\n",
    "   \"action\": \"create_group\",\n",
    "   \"title\": \"Esempio\",\n",
    "   \"members\": [\n",
    "    \"Steffo\"\n",
    "   ],\n",
    "   \"text\": \"\",\n",
    "   \"text_entities\": []\n",
    "  },\n",
    "  {\n",
    "   \"id\": 1531671,\n",
    "   \"type\": \"message\",\n",
    "   \"date\": \"2022-12-02T14:49:11\",\n",
    "   \"date_unixtime\": \"1669988951\",\n",
    "   \"from\": \"Steffo\",\n",
    "   \"from_id\": \"user25167391\",\n",
    "   \"text\": \"Questo è un messaggio di esempio.\",\n",
    "   \"text_entities\": [\n",
    "    {\n",
    "     \"type\": \"plain\",\n",
    "     \"text\": \"Questo è un messaggio di esempio.\"\n",
    "    }\n",
    "   ]\n",
    "  }\n",
    " ]\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importazione dati"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il file esportato da Telegram contiene tutte le informazioni di ogni evento di quella chat, inclusi gli autori e i contenuti dei messaggi: sono **dati sensibili**, e non possono essere inclusi per motivi di privacy.\n",
    "\n",
    "Visto però che l'unico dato rilevante ai fini di questa ricerca è la **data di invio di ciascun messaggio**, tutte le informazioni possono essere rimosse dal dataset, rendendolo così privo di informazioni sensibili."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si definisce una funzione, `anonymize_telegram`, in grado di leggere i file JSON esportati da Telegram e di restituire da essi una lista di date in cui sono stati inviati messaggi."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def anonymize_telegram(fd: t.IO[str]) -> list[datetime.datetime]:\n",
    "   \"\"\"\n",
    "   Read a Telegram GDPR export file, stripping everything but the messages' dates from it, returning a :class:`list` of :class:`datetime.datetime`s.\n",
    "\n",
    "   :param fd: The input file descriptor.\n",
    "   :returns:\n",
    "   \"\"\"\n",
    "   data = json.load(fd)\n",
    "   msgs = data[\"messages\"]\n",
    "\n",
    "   def msg_to_date(msg: dict[str, t.Any]) -> datetime.datetime:\n",
    "      \"\"\"\n",
    "      Convert a message :class:`dict` to the :class:`datetime.datetime` of its creation.\n",
    "\n",
    "      :param msg: The message to convert.\n",
    "      :return: The resulting :class:`datetime.datetime`.\n",
    "      \"\"\"\n",
    "      return datetime.datetime.fromisoformat(msg[\"date\"])\n",
    "\n",
    "   return list(map(msg_to_date, msgs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si fornisce un esempio del funzionamento di questa funzione:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/telegram/example.json\") as file:\n",
    "   telegram_example = anonymize_telegram(file)\n",
    "\n",
    "telegram_example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I dati così anonimizzati possono essere allegati alla relazione: si definisce una funzione `store_telegramanon` in grado di archiviare le liste di date create dalla precedente funzione in un file formato Pickle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def store_telegramanon(l: list[datetime.datetime], fd: t.IO[bytes]) -> None:\n",
    "   \"\"\"\n",
    "   Store a :class:`list` generated by :func:`anonymize_telegram` in a binary file descriptor.\n",
    "\n",
    "   :param l: The :class:`list` to store.\n",
    "   :param fd: The file descriptor to write to.\n",
    "   \"\"\"\n",
    "   pickle.dump(l, fd)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si fornisce un esempio del funzionamento di questa funzione:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/telegramanon/example.pickle\", \"wb\") as file:\n",
    "   store_telegramanon(telegram_example, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Infine, si definisce una funzione, `import_telegramanon`, in grado di leggere i dati precedentemente archiviati in un [`pandas.DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def import_telegramanon(fd: t.IO[bytes]) -> pandas.DataFrame:\n",
    "   \"\"\"\n",
    "   Import a :class:`list` stored by :func:`store_telegramanon` into a :class:`pandas.DataFrame`.\n",
    "\n",
    "   :param fd: The file descriptor to read from.\n",
    "   :return: The imported :class:`pandas.Series`.\n",
    "   \"\"\"\n",
    "   data = pickle.load(fd)\n",
    "   return pandas.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ancora, si fornisce un esempio del funzionamento di questa funzione:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/telegramanon/example.pickle\", \"rb\") as file:\n",
    "   telegramanon_example = import_telegramanon(file)\n",
    "\n",
    "telegramanon_example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dipartimento della Protezione Civile della Presidenza del Consiglio dei Ministri"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il Dipartimento della Protezione Civile [mette a disposizione un repository Git contenente i dati relativi alla diffusione del COVID-19 in Italia](https://github.com/pcm-dpc/COVID-19).\n",
    "\n",
    "All'interno del repository Git, i dati sono disponibili in formato CSV."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il repository è allegato a questo progetto come Git Submodule.\n",
    "\n",
    "Essendo di dimensioni significative, di default non viene scaricato da Git, ma è possibile effetuarne il download con i seguente comandi:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "!git submodule init\n",
    "!git submodule update"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Esempio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si allega un esempio di file CSV presente all'interno del repository:\n",
    "\n",
    "```csv\n",
    "data,stato,ricoverati_con_sintomi,terapia_intensiva,totale_ospedalizzati,isolamento_domiciliare,totale_positivi,variazione_totale_positivi,nuovi_positivi,dimessi_guariti,deceduti,casi_da_sospetto_diagnostico,casi_da_screening,totale_casi,tamponi,casi_testati,note,ingressi_terapia_intensiva,note_test,note_casi\n",
    "2020-02-24T18:00:00,ITA,101,26,127,94,221,0,221,1,7,,,229,4324,,,,,\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importazione dati"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ai fini di questa relazione, si è particolarmente interessati ai dati contenuti nel file `data/covid19/dati-json/dpc-covid19-ita-andamento-nazionale.json`, che contiene le statistiche delle infezioni di COVID-19 a livello nazionale."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si definisce una funzione `import_covid19`, che importa i dati di quel file JSON in un [`pandas.DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def import_covid19(fd: t.IO[str]) -> pandas.DataFrame:\n",
    "   \"\"\"\n",
    "   Import data from the given file descriptor to ``dpc-covid19-ita-andamento-nazionale.json`` into a :class:`pandas.DataFrame`.\n",
    "\n",
    "   :param fd: The file descriptor.\n",
    "   :return: The :class:`pandas.DataFrame`.\n",
    "   \"\"\"\n",
    "   return pandas.read_json(fd)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si effettua immediatamente l'importazione dei dati nella variabile `covid19_frame`, trovandosi essi in un file unico:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/covid19/dati-json/dpc-covid19-ita-andamento-nazionale.json\") as file:\n",
    "   covid19_frame = import_covid19(file)\n",
    "\n",
    "covid19_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
